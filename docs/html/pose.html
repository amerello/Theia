<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    

    <title>Pose and Resectioning &mdash; Theia Documentation</title>

<meta name="viewport" content="width=device-width; initial-scale=1.0; maximum-scale=1.0; user-scalable=0;"/>

<!-- Google Analytics Code -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-46196711-1', 'ucsb.edu');
  ga('send', 'pageview');

</script>


    
    <link rel="stylesheet" href="_static/rtd.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
  MathJax.Hub.Config({
    "HTML-CSS": {
      availableFonts: ["TeX"]
    }
  });
</script>
    <script type="text/javascript" src="_static/searchtools.js"></script>
    <link rel="top" title="Theia Documentation" href="index.html" />
    <link rel="up" title="Documentation" href="documentation.html" />
    <link rel="next" title="Math" href="math.html" />
    <link rel="prev" title="Ransac" href="ransac.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="math.html" title="Math"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="ransac.html" title="Ransac"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">Theia Documentation</a> &raquo;</li>
          <li><a href="documentation.html" accesskey="U">Documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="pose-and-resectioning">
<span id="documentation-pose"></span><h1>Pose and Resectioning<a class="headerlink" href="#pose-and-resectioning" title="Permalink to this headline">¶</a></h1>
<p>Theia contains efficient and robust implementations of the following pose and
resectioning algorithms. We attempted to make each method as general as possible so that users were not tied to Theia data structures to use the methods. The interface for all pose methods uses Eigen types for feature positions, 3D positions, and pose rotations and translations.</p>
<ul class="simple">
<li><a class="reference internal" href="#section-p3p"><em>Perspective Three Point (P3P)</em></a></li>
<li><a class="reference internal" href="#section-five-point-essential-matrix"><em>Five Point Relative Pose</em></a></li>
<li><a class="reference internal" href="#section-four-point-homography"><em>Four Point Algorithm for Homography</em></a></li>
<li><a class="reference internal" href="#section-eight-point"><em>Eight Point Algorithm for Fundamental Matrix</em></a></li>
<li><a class="reference internal" href="#section-dls-pnp"><em>Perspective N-Point</em></a></li>
<li><a class="reference internal" href="#section-four-point-focal-length"><em>Four Point Focal Length</em></a></li>
<li><a class="reference internal" href="#section-five-point-focal-length-radial-distortion"><em>Five Point Focal Length and Radial Distortion</em></a></li>
</ul>
<div class="section" id="perspective-three-point-p3p">
<span id="section-p3p"></span><h2>Perspective Three Point (P3P)<a class="headerlink" href="#perspective-three-point-p3p" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><dl class="function">
<dt id="PoseFromThreePoints__Eigen::Vector2dCA.Eigen::Vector3dCA.std::vector:Eigen::Matrix3d:P.std::vector:Eigen::Vector3d:P">
bool <tt class="descname">PoseFromThreePoints</tt><big>(</big>const Eigen::Vector2d <em>feature_position</em>[3], const Eigen::Vector3d <em>world_point</em>[3], std::vector&lt;Eigen::Matrix3d&gt;* <em>solution_rotations</em>, std::vector&lt;Eigen::Vector3d&gt;* <em>solution_translations</em><big>)</big><a class="headerlink" href="#PoseFromThreePoints__Eigen::Vector2dCA.Eigen::Vector3dCA.std::vector:Eigen::Matrix3d:P.std::vector:Eigen::Vector3d:P" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes camera pose using the three point algorithm and returns all
possible solutions (up to 4). Follows steps from the paper &#8220;A Novel
Parameterization of the Perspective-Three-Point Problem for a direct
computation of Absolute Camera position and Orientation&#8221; by <a class="reference internal" href="bibliography.html#kneip" id="id1">[Kneip]</a>. This
algorithm has been proven to be up to an order of magnitude faster than
other methods. The output rotation and translation define world-to-camera
transformation.</p>
<p><tt class="docutils literal"><span class="pre">feature_position</span></tt>: Image points corresponding to model points. These should be
calibrated image points as opposed to pixel values.</p>
<p><tt class="docutils literal"><span class="pre">world_point</span></tt>: 3D location of features.</p>
<p><tt class="docutils literal"><span class="pre">solution_rotations</span></tt>: the rotation matrix of the candidate solutions</p>
<p><tt class="docutils literal"><span class="pre">solution_translation</span></tt>: the translation of the candidate solutions</p>
<p><tt class="docutils literal"><span class="pre">returns</span></tt>: Whether the pose was computed successfully, along with the
output parameters <tt class="docutils literal"><span class="pre">rotation</span></tt> and <tt class="docutils literal"><span class="pre">translation</span></tt> filled with the valid
poses.</p>
</dd></dl>

</div></blockquote>
</div>
<div class="section" id="five-point-relative-pose">
<span id="section-five-point-essential-matrix"></span><h2>Five Point Relative Pose<a class="headerlink" href="#five-point-relative-pose" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><dl class="function">
<dt id="FivePointRelativePose__Eigen::Vector2dCA.Eigen::Vector2dCA.std::vector:Eigen::Matrix3d:P.std::vector:Eigen::Vector3d:P">
bool <tt class="descname">FivePointRelativePose</tt><big>(</big>const Eigen::Vector2d <em>image1_points</em>[5], const Eigen::Vector2d <em>image2_points</em>[5], std::vector&lt;Eigen::Matrix3d&gt;* <em>rotation</em>, std::vector&lt;Eigen::Vector3d&gt;* <em>translation</em><big>)</big><a class="headerlink" href="#FivePointRelativePose__Eigen::Vector2dCA.Eigen::Vector2dCA.std::vector:Eigen::Matrix3d:P.std::vector:Eigen::Vector3d:P" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the relative pose between two cameras using 5 corresponding
points. Algorithm is implemented based on &#8220;An Efficient Solution to the
Five-Point Relative Pose Problem&#8221; by <a class="reference internal" href="bibliography.html#nister" id="id2">[Nister]</a>. The rotation and translation
returned are defined such that <span class="math">\(E=[t]_{\times} * R\)</span> and
<span class="math">\(y^\top * E * x = 0\)</span> where <span class="math">\(y\)</span> are points from image2 and
<span class="math">\(x\)</span> are points from image1.</p>
<p><tt class="docutils literal"><span class="pre">image1_points</span></tt>: Location of features on the image plane of image 1.</p>
<p><tt class="docutils literal"><span class="pre">image2_points</span></tt>: Location of features on the image plane of image 2.</p>
<p><tt class="docutils literal"><span class="pre">returns</span></tt>: Output the number of poses computed as well as the relative
rotation and translation.</p>
</dd></dl>

</div></blockquote>
</div>
<div class="section" id="four-point-algorithm-for-homography">
<span id="section-four-point-homography"></span><h2>Four Point Algorithm for Homography<a class="headerlink" href="#four-point-algorithm-for-homography" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><dl class="function">
<dt id="FourPointHomography__std::vector:Eigen::Vector2d:CR.std::vector:Eigen::Vector2d:CR.Eigen::Matrix3dP">
bool <tt class="descname">FourPointHomography</tt><big>(</big>const std::vector&lt;Eigen::Vector2d&gt;&amp; <em>image_1_points</em>, const std::vector&lt;Eigen::Vector2d&gt;&amp; <em>image_2_points</em>, Eigen::Matrix3d* <em>homography</em><big>)</big><a class="headerlink" href="#FourPointHomography__std::vector:Eigen::Vector2d:CR.std::vector:Eigen::Vector2d:CR.Eigen::Matrix3dP" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the 2D <a class="reference external" href="http://en.wikipedia.org/wiki/Homography_(computer_vision)">homography</a> mapping points
in image 1 to image 2 such that: <span class="math">\(x' = Hx\)</span> where <span class="math">\(x\)</span> is a point in
image 1 and <span class="math">\(x'\)</span> is a point in image 2. The algorithm implemented is
the DLT algorithm based on algorithm 4.2 in <a class="reference internal" href="bibliography.html#hartleyzisserman" id="id3">[HartleyZisserman]</a>.</p>
<p><tt class="docutils literal"><span class="pre">image_1_points</span></tt>: Image points from image 1. At least 4 points must be
passed in.</p>
<p><tt class="docutils literal"><span class="pre">image_2_points</span></tt>: Image points from image 2. At least 4 points must be
passed in.</p>
<p><tt class="docutils literal"><span class="pre">homography</span></tt>: The computed 3x3 homography matrix.</p>
</dd></dl>

</div></blockquote>
</div>
<div class="section" id="eight-point-algorithm-for-fundamental-matrix">
<span id="section-eight-point"></span><h2>Eight Point Algorithm for Fundamental Matrix<a class="headerlink" href="#eight-point-algorithm-for-fundamental-matrix" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><dl class="function">
<dt id="NormalizedEightPoint__std::vector:Eigen::Vector2d:CR.std::vector:Eigen::Vector2d:CR.Eigen::Matrix3dP">
bool <tt class="descname">NormalizedEightPoint</tt><big>(</big>const std::vector&lt;Eigen::Vector2d&gt;&amp; <em>image_1_points</em>, const std::vector&lt;Eigen::Vector2d&gt;&amp; <em>image_2_points</em>, Eigen::Matrix3d* <em>fundamental_matrix</em><big>)</big><a class="headerlink" href="#NormalizedEightPoint__std::vector:Eigen::Vector2d:CR.std::vector:Eigen::Vector2d:CR.Eigen::Matrix3dP" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the <a class="reference external" href="http://en.wikipedia.org/wiki/Fundamental_matrix_(computer_vision)">fundamental matrix</a> relating
image points between two images such that <span class="math">\(x' F x = 0\)</span> for all
correspondences <span class="math">\(x\)</span> and <span class="math">\(x'\)</span> in images 1 and 2 respectively. The
normalized eight point algorithm is a speedy estimation of the fundamental
matrix (Alg 11.1 in <a class="reference internal" href="bibliography.html#hartleyzisserman" id="id4">[HartleyZisserman]</a>) that minimizes an algebraic error.</p>
<p><tt class="docutils literal"><span class="pre">image_1_points</span></tt>: Image points from image 1. At least 8 points must be
passed in.</p>
<p><tt class="docutils literal"><span class="pre">image_2_points</span></tt>: Image points from image 2. At least 8 points must be
passed in.</p>
<p><tt class="docutils literal"><span class="pre">fundamental_matrix</span></tt>: The computed fundamental matrix.</p>
<p><tt class="docutils literal"><span class="pre">returns:</span></tt> true on success, false on failure.</p>
</dd></dl>

<dl class="function">
<dt id="GoldStandardEightPoint__std::vector:Eigen::Vector2d:CR.std::vector:Eigen::Vector2d:CR.Eigen::Matrix3dP">
bool <tt class="descname">GoldStandardEightPoint</tt><big>(</big>const std::vector&lt;Eigen::Vector2d&gt;&amp; <em>image_1_points</em>, const std::vector&lt;Eigen::Vector2d&gt;&amp; <em>image_2_points</em>, Eigen::Matrix3d* <em>fundamental_matrix</em><big>)</big><a class="headerlink" href="#GoldStandardEightPoint__std::vector:Eigen::Vector2d:CR.std::vector:Eigen::Vector2d:CR.Eigen::Matrix3dP" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the <a class="reference external" href="http://en.wikipedia.org/wiki/Fundamental_matrix_(computer_vision)">fundamental matrix</a>
relating image points between two images such that <span class="math">\(x' F x = 0\)</span> for
all correspondences <span class="math">\(x\)</span> and <span class="math">\(x'\)</span> in images 1 and 2
respectively. The gold standard algorithm computes an initial estimation of
the fundmental matrix from the <a class="reference internal" href="#NormalizedEightPoint__std::vector:Eigen::Vector2d:CR.std::vector:Eigen::Vector2d:CR.Eigen::Matrix3dP" title="NormalizedEightPoint"><tt class="xref cpp cpp-func docutils literal"><span class="pre">NormalizedEightPoint()</span></tt></a> then uses
Levenberg-Marquardt to minimize the geometric error (i.e., reprojection
error) according to algorithm 11.3 in <a class="reference internal" href="bibliography.html#hartleyzisserman" id="id6">[HartleyZisserman]</a>.</p>
<p><tt class="docutils literal"><span class="pre">image_1_points</span></tt>: Image points from image 1. At least 8 points must be
passed in.</p>
<p><tt class="docutils literal"><span class="pre">image_2_points</span></tt>: Image points from image 2. At least 8 points must be
passed in.</p>
<p><tt class="docutils literal"><span class="pre">fundamental_matrix</span></tt>: The computed fundamental matrix.</p>
<p><tt class="docutils literal"><span class="pre">returns:</span></tt> true on success, false on failure.</p>
</dd></dl>

</div></blockquote>
</div>
<div class="section" id="perspective-n-point">
<span id="section-dls-pnp"></span><h2>Perspective N-Point<a class="headerlink" href="#perspective-n-point" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><dl class="function">
<dt id="DlsPnp__std::vector:Eigen::Vector2d:CR.std::vector:Eigen::Vector3d:CR.std::vector:Eigen::Quaterniond:P.std::vector:Eigen::Vector3d:P">
void <tt class="descname">DlsPnp</tt><big>(</big>const std::vector&lt;Eigen::Vector2d&gt;&amp; <em>feature_position</em>, const std::vector&lt;Eigen::Vector3d&gt;&amp; <em>world_point</em>, std::vector&lt;Eigen::Quaterniond&gt;* <em>solution_rotation</em>, std::vector&lt;Eigen::Vector3d&gt;* <em>solution_translation</em><big>)</big><a class="headerlink" href="#DlsPnp__std::vector:Eigen::Vector2d:CR.std::vector:Eigen::Vector3d:CR.std::vector:Eigen::Quaterniond:P.std::vector:Eigen::Vector3d:P" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the camera pose using the Perspective N-point method from &#8220;A Direct
Least-Squares (DLS) Method for PnP&#8221; by <a class="reference internal" href="bibliography.html#hesch" id="id7">[Hesch]</a> and Stergios Roumeliotis. This
method is extremely scalable and highly accurate for the PnP problem. A
minimum of 4 points are required, but there is no maximum number of points
allowed as this is a least-squared approach. Theoretically, up to 27 solutions
may be returned, but in practice only 4 real solutions arise and in almost all
cases where n &gt;= 6 there is only one solution which places the observed points
in front of the camera. The returned rotation and translations are
world-to-camera transformations.</p>
<p><tt class="docutils literal"><span class="pre">feature_position</span></tt>: Normalized image rays corresponding to model points. Must
contain at least 4 points.</p>
<p><tt class="docutils literal"><span class="pre">points_3d</span></tt>: 3D location of features. Must correspond to the image_ray of
the same index. Must contain the same number of points as image_ray, and at
least 4.</p>
<p><tt class="docutils literal"><span class="pre">solution_rotation</span></tt>: the rotation quaternion of the candidate solutions</p>
<p><tt class="docutils literal"><span class="pre">solution_translation</span></tt>: the translation of the candidate solutions</p>
</dd></dl>

</div></blockquote>
</div>
<div class="section" id="four-point-focal-length">
<span id="section-four-point-focal-length"></span><h2>Four Point Focal Length<a class="headerlink" href="#four-point-focal-length" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><dl class="function">
<dt id="FourPointPoseAndFocalLength__std::vector:Eigen::Vector2d:CR.std::vector:Eigen::Vector3d:CR.std::vector:Eigen::Matrix:double.3.4::P">
int <tt class="descname">FourPointPoseAndFocalLength</tt><big>(</big>const std::vector&lt;Eigen::Vector2d&gt;&amp; <em>feature_positions</em>, const std::vector&lt;Eigen::Vector3d&gt;&amp; <em>world_points</em>, std::vector&lt;Eigen::Matrix&lt;double, 3, 4&gt;&gt;* <em>projection_matrices</em><big>)</big><a class="headerlink" href="#FourPointPoseAndFocalLength__std::vector:Eigen::Vector2d:CR.std::vector:Eigen::Vector3d:CR.std::vector:Eigen::Matrix:double.3.4::P" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the camera pose and unknown focal length of an image given four 2D-3D
correspondences, following the method of <a class="reference internal" href="bibliography.html#bujnak" id="id8">[Bujnak]</a>. This method involves
computing a grobner basis from a modified constraint of the focal length and
pose projection.</p>
<p><tt class="docutils literal"><span class="pre">feature_position</span></tt>: Normalized image rays corresponding to model points. Must
contain at least 4 points.</p>
<p><tt class="docutils literal"><span class="pre">points_3d</span></tt>: 3D location of features. Must correspond to the image_ray of
the same index. Must contain the same number of points as image_ray, and at
least 4.</p>
<p><tt class="docutils literal"><span class="pre">projection_matrices</span></tt>: The solution world-to-camera projection matrices,
inclusive of the unknown focal length. For a focal length f and a camera
calibration matrix <span class="math">\(K=diag(f, f, 1)\)</span>, the projection matrices returned
are of the form <span class="math">\(P = K * [R | t]\)</span>.</p>
</dd></dl>

</div></blockquote>
</div>
<div class="section" id="five-point-focal-length-and-radial-distortion">
<span id="section-five-point-focal-length-radial-distortion"></span><h2>Five Point Focal Length and Radial Distortion<a class="headerlink" href="#five-point-focal-length-and-radial-distortion" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><dl class="function">
<dt id="FivePointFocalLengthRadialDistortion__std::vector:Eigen::Vector2d:CR.std::vector:Eigen::Vector3d:CR.iC.std::vector:Eigen::Matrix:double.3.4::P.std::vector:std::vector:double::P">
bool <tt class="descname">FivePointFocalLengthRadialDistortion</tt><big>(</big>const std::vector&lt;Eigen::Vector2d&gt;&amp; <em>feature_positions</em>, const std::vector&lt;Eigen::Vector3d&gt;&amp; <em>world_points</em>, const int <em>num_radial_distortion_params</em>, std::vector&lt;Eigen::Matrix&lt;double, 3, 4&gt;&gt;* <em>projection_matrices</em>, std::vector&lt;std::vector&lt;double&gt;&gt;* <em>radial_distortions</em><big>)</big><a class="headerlink" href="#FivePointFocalLengthRadialDistortion__std::vector:Eigen::Vector2d:CR.std::vector:Eigen::Vector3d:CR.iC.std::vector:Eigen::Matrix:double.3.4::P.std::vector:std::vector:double::P" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the absolute pose, focal length, and radial distortion of a camera
using five 3D-to-2D correspondences <a class="reference internal" href="bibliography.html#kukelova" id="id9">[Kukelova]</a>. The method solves for the
projection matrix (up to scale) by using a cross product constraint on the
standard projection equation. This allows for simple solution to the first two
rows of the projection matrix, and the third row (which contains the focal
length and distortion parameters) can then be solved with SVD on the remaining
constraint equations from the first row of the projection matrix. See the
paper for more details.</p>
<p><tt class="docutils literal"><span class="pre">feature_positions</span></tt>: the 2D location of image features. Exactly five
features must be passed in.</p>
<p><tt class="docutils literal"><span class="pre">world_points</span></tt>: 3D world points corresponding to the features
observed. Exactly five points must be passed in.</p>
<dl class="docutils">
<dt><tt class="docutils literal"><span class="pre">num_radial_distortion_params</span></tt>: The number of radial distortion paramters to</dt>
<dd>solve for. Must be 1, 2, or 3.</dd>
<dt><tt class="docutils literal"><span class="pre">projection_matrices</span></tt>: Camera projection matrices (that encapsulate focal</dt>
<dd>length). These solutions are only valid up to scale.</dd>
</dl>
<p><tt class="docutils literal"><span class="pre">radial_distortions</span></tt>: Each entry of this vector contains a vector with the
radial distortion parameters (up to 3, but however many were specified in
<tt class="docutils literal"><span class="pre">num_radial_distortion_params</span></tt>).</p>
<p><tt class="docutils literal"><span class="pre">return</span></tt>: true if successful, false if not.</p>
</dd></dl>

</div></blockquote>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/theia_logo.png" alt="Logo"/>
            </a></p>

<h3><a href="index.html">Theia</a></h3>

  <h4>Previous topic</h4>
  <p class="topless"><a href="ransac.html"
                        title="previous chapter">Ransac</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="math.html"
                        title="next chapter">Math</a></p>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="math.html" title="Math"
             >next</a> |</li>
        <li class="right" >
          <a href="ransac.html" title="Ransac"
             >previous</a> |</li>
        <li><a href="index.html">Theia Documentation</a> &raquo;</li>
          <li><a href="documentation.html" >Documentation</a> &raquo;</li> 
      </ul>
    </div>
<div class="footer">
    &copy; Copyright 2014, Chris Sweeney.
</div>


  </body>
</html>